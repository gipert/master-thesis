%! TEX root = ../main.tex
\section*{Introduction}
\addcontentsline{toc}{section}{\hspace{1.5em}Introduction}
	%The Standard Model of particle Physics, which describes the particles we now believe to be fundamental and their interactions, represents one of the greatest successes of Physics of the last century. From the beginning of the debate towards the particle or wave nature of light to the very recent discovery of the Higgs boson it allowed physicists to make powerful and precise prediction later strongly confirmed by experimental evidences. First came quantum electrodynamics, developed in the 1930s, then the model was unified with weak interactions by Glashow in 1961 and finally provided with the Higgs mechanism by Weinberg and Salam in 1967. The Standard Model also includes quantum chromodynamics, the theory of strong interactions. In the past few decades, however, experimental evidences brought to light new phenomena, not predicted by the Standard Model, that suggested the presence of some new Physics beyond the well-established existing theoretical framework. Also, the usual prescriptions of the quantum field theory cannot produce a valid theory of quantum gravity, and nowadays the solution to this problem is an active research topic. The Standard Model is very far from being the last word: there are still many gaps in our understanding, as we shall see later.

	The initial purpose of unifying Special Relativity and Quantum Mechanics has led to the establishment of one of the building blocks of the theory behind the Standard Model: its invariance with respect to linear transformations of space-time, the so-called Lorentz transformations. Lorentz was one of the first to study the invariance laws of Maxwell's equations and some years later Einstein showed that these transformations were a natural consequence of the foundations of Special Relativity, namely the constantness of the speed of light in every inertial frame of reference. However, recent research activities in Quantum Gravity show that this symmetry is in fact nothing sacred, and its breakdown at the Planck scale cannot be excluded. Lorentz symmetry is also strongly tied to CPT symmetry (the combination of Charge, Parity and Time-reversal transformations) by the CPT theorem. This theorem states that every local, relativistic quantum field theory must be CPT invariant.

	The neutrino is playing the role of a messenger of the new Physics beyond the Standard Model. Studying the properties and interactions of neutrinos has been one of the most exciting and vigorous activities in Particle Physics and Astrophysics ever since Pauli first proposed their existence in 1930. In spite of their weakly interacting nature, we have so far accumulated an enormous amount of knowledge about them. No experiments that have been performed so far have detected conclusive deviations from the Standard Model, except neutrino oscillation experiments, which have shown that neutrinos are massive and mixed. The understanding of how the neutrinos would gain tiny masses and how they are mixed is an extremely challenging task that we have to face. The consequences could make the Standard Model an effective theory of the yet unknown theory beyond it.

	An open question of fundamental importance concerns the nature of these particles, which could be either of Dirac or Majorana type (i.e.~neutrino and anti-neutrino are distinct particles or the same particle). An attempt to address this problem is done by experiments looking for the neutrinoless mode of double-beta decay. The double-beta decay, in its two-neutrino Standard Model mode ($2\nbb$), consists in a nucleus that decays into a daughter nucleus with two electrons and two electron-anti-neutrinos as a byproduct. If the neutrino is a Majorana particle then another mode may occur ($0\nbb$), in which neutrinos are not produced at all. Neutrinoless double-beta decay experiments are considered the most promising way to solve the enigma, although these events are very rare processes controlled by weak interactions. One of these is the {\gerda} experiment, located at LNGS in Italy at a depth of 3500 m w.e. (water equivalent). {\gerda} submerses bare high-purity germanium detectors enriched in \ce{^{76}Ge} into liquid argon (LAr), which serves simultaneously as a shield against external radioactivity and as a cooling medium, in order to substantially reduce background events. In these types of experiments the source is equal to the detector which yields high detection efficiency, allowing to reach a superior energy resolution and enhance the ability to discriminate background from signal.

	A careful study of the two-neutrino double-beta decay is also performed by these experiments. The high precision that many of them have reached has motivated the formulation of different modes of double-beta decay so that experiments can also look for new Physics through unconventional decay modes. As quoted above, the spontaneous breakdown of the Lorentz symmetry is an interesting feature that can be accommodated by many candidate theories of Quantum Gravity, such as String Theory. The general framework that incorporates operators that break Lorentz invariance in the Standard Model is the Standard Model Extension. This effective field theory parametrizes generic deviations from Lorentz invariance in the form of coordinate-invariant terms in the action by contracting operators of conventional fields with controlling coefficients for Lorentz violation. It should be noted that a subset of operators in the Standard Model Extension also breaks CPT symmetry. All quantum field operators for Lorentz violation involved in the propagation of neutrinos have been classified and enumerated. Their effects show up in neutrino oscillations experiments and time-of-flight experiments. However, four operators, odd under CPT, cannot be detected in this way, instead, they must be accessed through physical processes that involve neutrino phase-space properties, such as particle decays. The net effect on the energy spectrum of the decay products is a distortion regulated by a combination of the four operators' coefficients, denoted with $\aof$.

	In this work we study the summed energy spectrum of the electrons produced in $2\nbb$ detected by the {\gerda} experiment, in order to extract an upper limit for $\aof$. In order to accomplish this, background modeling is an essential step: starting from the screening measurements of the radioactivity inside {\gerda}â€™s components, energy spectra of various background sources are simulated inside the apparatus taking its geometry into account. Then, the presence of the isotopes is tested by fitting the simulated spectra of different contributions to the measured energy spectrum with a Bayesian statistical analysis. Data from the screening measurements of the {\gerda} components are used to set prior distributions on the activities of the background sources, and a p-value is used to provide a goodness-of-fit criterion. The presence of all the hypothetical contaminations is tested in a maximal model that contains all possible contributions; then a minimal model is built ruling out step-by-step the sources indicated as possibly absent by the fitting procedure. The Background Index (BI), namely the number of counts over units of energy, mass and time in the Region of Interest (\textsc{RoI}) around the Q-value of $2\nbb$, is estimated for all the background contributions. With this minimal background model, the half-life of $2\nbb$ is extracted only considering the Standard Model contribution, then the CPT-violating mode is included, and an upper limit on $\aof$ computed.

	In \cref{sec:theory} all the theoretical notions that underlie the phenomenon under study are detailed, then a description of the {\gerda} experimental setup is given in \cref{sec:gerda}. We provide a description of the data sets and the Monte Carlo simulations in \cref{sec:data} and a description of the statistical methodology in \cref{sec:bayes}. Finally, the results of the analysis are presented in \cref{sec:results}.
